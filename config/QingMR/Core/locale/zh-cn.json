{
	"Cluster properties" : "集群属性",
	"name" : "名称",
	"The name of the service" : "服务名称",
	"description" : "描述",
	"The description of the service" : "服务描述",
	"VxNet" : "私有网络",
	"Choose a vxnet to join" : "选择应用运行的私有网络",
	"Choose another application service to use, all the nodes in this external service will be added to hosts of current application service" : "选择需要依赖的其他应用服务，该服务里的所有节点将被添加到当前应用服务所有节点的hosts文件里，通常用于依赖的 HBase 服务（非必填项）",
	"CPUs of each node" : "每个节点的CPU数量",
	"Memory" : "内存",
	"memory of each node (in MB)" : "每个节点的内存大小（单位MB）",
	"count" : "节点数量",
	"Number of nodes for the cluster to create" : "待创建集群里该类节点数量",
	"instance class" : "节点类型",
	"The instance type for the cluster to run, such as Enterprise" : "节点为企业型",
	"The instance type for the cluster to run, such as Standard" : "节点为基础型",
	"volume class" : "数据盘类型",
	"The volume type for each instance, such as Enterprise SSD" : "数据盘为SSD企业级",
	"The volume type for each instance, such as Enterprise SSD, NeonSAN" : "数据盘分为SSD企业级、企业级分布式 SAN (NeonSAN)",
	"The volume type for each instance, such as Standard" : "数据盘为基础型",
	"volume size" : "节点容量",
	"The volume size for each instance" : "节点总存储空间大小", 
	"HDFS master" : "HDFS主节点",
    "YARN master" : "主节点",
	"Bigdata client" : "Client节点",
	"HDFS master properties" : "HDFS主节点(Name Node)属性",
	"slave" : "从节点",
	"Slave properties" : "从节点（包含Spark worker, Yarn NodeManager和HDFS Data Node）属性",
	"BigData client" : "BigData client节点",
	"BigData client properties" : "BigData client节点属性",
	"Service properties" : "服务属性",
	"The number of server threads for the data node" : "Data node节点服务线程数",
	"The number of server threads for the name node" : "Name node节点服务线程数",
	"The replication factor in HDFS" : "HDFS副本数",
	"It controls the number of minutes after which a trash checkpoint directory is deleted" : "控制Trash检查点目录过多少分钟后被删除",
	"SparkWorkers" : "Workers(Spark Standalone模式)",
	"SparkApps" : "Applications(Spark Standalone模式)",
	"WorkersTotal" : "Total",
	"WorkersAlive" : "Alive",
	"FilesTotal" : "Total",
	"FilesCreated" : "Created",
	"FilesAppended" : "Appended",
	"FilesRenamed" : "Renamed",
	"FilesDeleted" : "Deleted",
	"RemainingGB" : "Remaining",
	"LiveNodes" : "Live",
	"DeadNodes" : "Dead",
	"DecomLiveNodes" : "DecomLive",
	"DecomDeadNodes" : "DecomDead",
	"DecommissioningNodes" : "Decommissioning",
	"MemUsedMB" : "Used",
	"MemFreeMB" : "Free",
	"BlocksRead" : "Read",
	"BlocksWritten" : "Written",
	"NMMemory" : "NodeManager内存",
	"AllocatedGB" : "Allocated",
	"AvailableGB" : "Available",
	"Compute" : "计算(Spark Standalone)",
	"WorkerMemory" : "内存(Spark Standalone)",
	"Storage" : "存储",
	"Blocks" : "DFS块",
	"Gc" : "垃圾回收",
	"DFS Files" : "DFS文件",
	"DFS Percentage" : "DFS空间占比",
	"DFS Capacity" : "DFS容量",
	"NodeManagers" : "YARN Node Managers",
	"NumActiveNMs" : "Actives",
	"NumDecommissionedNMs" : "Decommissioned",
	"NumLostNMs" : "Lost",
	"NumUnhealthyNMs" : "Unhealthy",
	"NumRebootedNMs" : "Rebooted",
	"Running" : "运行中的YARN应用",
	"running_0" : "小于60分钟",
	"running_60" : "60~300分钟",
	"running_300" : "300~1440分钟",
	"running_1440" : "1440分钟以上",
	"Applications" : "YARN应用",
	"AppsSubmitted" : "Submitted",
	"AppsRunning" : "Running",
	"AppsPending" : "Pending",
	"AppsCompleted" : "Completed",
	"AppsFailed" : "Failed",
	"YarnMemory" : "YARN内存",
	"AllocatedMB" : "Allocated",
	"AvailableMB" : "Available",
	"ReservedMB" : "Reserved",
	"VirtualCores" : "YARN Virtual Cores",
	"AllocatedVCores" : "Allocated",
	"AvailableVCores" : "Available",
	"ReservedVCores" : "Reserved",
	"Containers" : "YARN Containers",
	"AllocatedContainers" : "Allocated",
	"ReservedContainers" : "Reserved",
	"ContainersIniting" : "Initing",
	"ContainersRunning" : "Running",
	"RunningApps" : "Running",
	"WaitingApps" : "Waiting",
	"Hadoop proxy user" : "Hadoop代理用户",
	"Hosts the proxyuser can represent" : "Hadoop代理用户能代理哪些hosts",
	"Groups in hosts the proxyuser can represent" : "Hadoop代理用户能代理指定host中的哪些groups",
	"Enable periodic cleanup of worker/application directories. Only the directories of stopped applications are cleaned up" : "定期清理应用work目录，运行中的application不会被清理。",
	"Controls the interval, in seconds, at which the worker cleans up old application work dirs on the local machine, default to 28800 seconds(8 hours)" : "清理应用work目录的时间间隔，以秒为单位，默认为28800秒（8小时）",
	"The number of seconds to retain application work directories on each worker, default to 86400 seconds(24 hours)" : "保留worker上应用work目录的时间，以秒为单位，默认为86400秒(24 小时)",
	"Memory(in MB) allocated to spark master daemon(standalone mode). The upper limit is total memory - 1024" : "Spark master进程(Standalone模式)占用内存(MB)。该值上限定为总内存-1024",
	"Memory(in MB) allocated to spark worker daemon(standalone mode). The upper limit is total memory - 1024" : "Spark worker进程(Standalone模式)占用内存(MB)。该值上限定为总内存-1024",
	"The maximum amount of heap(in MB) to use by resource manager. It will be reset to current available free memory if 1000 is specified" : "ResourceManager最大可用堆内存大小(MB)，如果指定1000，则ResourceManager将可利用当前所有空闲内存",
	"The maximum amount of heap to use by datanode in MB, Default is 1000. The upper limit is total memory - 1024" : "Datanode daemon进程最大可用堆内存大小(MB)，默认值为1000. 该值上限为总内存-1024",
	"Specify the python version used by a python spark job, current supported python versions are 2.7.13 and 3.6.1. Anaconda distribution data science packages numpy, scikit-learn, scipy, Pandas, NLTK and Matplotlib are also included." : "指定Python Spark程序所用的Python版本，目前支持Anaconda发行版的Python 2.7.13和3.6.1。两个Python版本对应的Anaconda发行版数据科学库numpy, scikit-learn, scipy, Pandas, NLTK和Matplotlib也包含在内",
	"Whether to enable spark standalone mode or not" : "是否开启Spark Standalone模式。开启后将可以以Spark Standalone模式提交Spark应用；关闭后可以以Spark on Yarn模式提交Spark应用；如仅以Spark on YARN模式提交Spark应用或者仅使用hadoop相关功能，则可以选择关闭Spark Standalone模式以释放资源。此选项最好不要和其他配置参数项一起改，单独改动此项然后保存设置是推荐的作法",
	"Whether to use QingStor or not" : "是否将 QingStor 与 Hadoop, Spark 及 Hive 集成，如需集成则必须输入相应的access_key及secret_key",
	"Specify QingStor zone, current available zones are pek3a, sh1a and pek3b." : "指定QingStor的分区，目前开放了pek3a,sh1a和pek3b, 其他分区何时开放请关注QingMR用户指南",
	"Scheduler mode within an spark application for parallel jobs that can run simultaneously if they were submitted from separate threads" : "Spark应用内调度模式，针对Spark应用内不同线程提交的可同时运行的任务",
	"The maximum amount of heap(in MB) to use by node manager. The upper limit is half of total memory" : "NodeManager最大可用堆内存大小(MB)，该值上限为总内存的一半",
	"The class to use as the resource scheduler" : "YARN ResourceManager调度器，默认为CapacityScheduler，可选FairScheduler。如果选择FairScheduler，需要上传自定义的fair-scheduler.xml到HDFS的/tmp/hadoop-yarn/目录，然后右键点击集群选择更新调度器。如需对CapacityScheduler的默认行为进行更改，同样需要上传自定义的capacity-scheduler.xml到HDFS的/tmp/hadoop-yarn/目录，然后更新调度器",
	"The number of threads used to handle applications manager requests" : "处理applications manager请求的线程数",
	"Number of threads used to launch/cleanup AM" : "启动/清理ApplicationMaster的线程数",
	"Number of threads to handle scheduler interface" : "处理scheduler接口请求的线程数",
	"Number of threads to handle resource tracker calls" : "处理resource tracker请求的线程数",
	"Number of threads used to handle RM admin interface" : "处理ResourceManager管理接口请求的线程数",
	"Number of threads container manager uses" : "分配给Container Manager用的线程数",
	"Number of threads used in cleanup" : "用于清理工作的线程数",
	"Number of threads to handle localization requests" : "用于处理localization请求的线程数",
	"Number of threads to use for localization fetching" : "用于处理localization fetching请求的线程数",
	"Whether physical memory limits will be enforced for containers." : "是否需要为container检查物理内存限制",
	"Whether virtual memory limits will be enforced for containers." : "是否需要为container检查虚拟内存限制",
	"The ratio of virtual memory to physical memory in node manager" : "NodeManager中虚拟内存与物理内存的比率",
	"The minimum allocation for every container request at the RM, in MBs. Memory requests lower than this will throw a InvalidResourceRequestException" : "ResourceManager中针对每个container请求内存的最小分配值(MB). 低于该值的内存请求将会抛出InvalidResourceRequestException异常",
	"The maximum allocation for every container request at the RM, in MBs. Memory requests higher than this will throw a InvalidResourceRequestException" : "ResourceManager中针对每个container请求内存的最大分配值(MB). 高于该值的内存请求将会抛出InvalidResourceRequestException异常",
	"The minimum allocation for every container request at the RM, in terms of virtual CPU cores. Requests lower than this will throw a InvalidResourceRequestException" : "ResourceManager中针对每个container请求virtual CPU cores的最小分配值。 低于该值的请求将会抛出InvalidResourceRequestException异常",
	"The maximum allocation for every container request at the RM, in terms of virtual CPU cores. Requests higher than this will throw a InvalidResourceRequestException" : "ResourceManager中针对每个container请求virtual CPU cores的最大分配值。 高于该值的请求将会抛出InvalidResourceRequestException异常",
	"Below yarn.scheduler.fair.* options are only valid when FairScheduler is used. Whether to use the username associated with the allocation as the default queue name, in the event that a queue name is not specified. If this is set to false or unset, all jobs have a shared default queue, named default" : "以下yarn.scheduler.fair.*相关选项只有在FairScheduler被使用时才生效。在资源请求中没有指定队列名字的时候，是否使用username作为默认的队列名。如果此选项被设置为false或者未设置，所有job都将共享一个名为default的队列",
	"Whether to use preemption or not" : "是否应用preemption",
	"The utilization threshold after which preemption kicks in. The utilization is computed as the maximum ratio of usage to capacity among all resources" : "超过指定集群资源利用率后将会激活preemption. 资源利用率是已用资源与资源容量的比率",
	"Whether to assign shares to individual apps based on their size, rather than providing an equal share to all apps regardless of size" : "是否根据应用的大小分配资源，而不是对所有应用无视大小分配同样的资源",
	"Whether to allow multiple container assignments in one heartbeat" : "是否允许在一次心跳中指定多个container",
	"If assignmultiple is true, the maximum amount of containers that can be assigned in one heartbeat. Defaults to -1, which sets no limit" : "如果assignmultiple为true，在一次心跳中可指定的最大container数量。设置为-1表示无限制",
	"For applications that request containers on particular nodes, the number of scheduling opportunities since the last container assignment to wait before accepting a placement on another node. Expressed as a float between 0 and 1, which, as a fraction of the cluster size, is the number of scheduling opportunities to pass up. The default value of -1.0 means don’t pass up any scheduling opportunities" : "对于请求某特定节点上container的应用，设定该值指定一个可错失的得到别的节点中container的机会。错失次数超过该值，该请求将得到别的节点的container. 以集群大小百分比的形式指定，-1表示不错失任何调度机会",
	"For applications that request containers on particular racks, the number of scheduling opportunities since the last container assignment to wait before accepting a placement on another rack. Expressed as a float between 0 and 1, which, as a fraction of the cluster size, is the number of scheduling opportunities to pass up. The default value of -1.0 means don’t pass up any scheduling opportunities" : "对于请求某特定rack上container的应用，设定该值指定一个可错失的得到别的rack中container的机会。错失次数超过该值，该请求将得到别的rack的container. 以集群大小百分比的形式指定，-1表示不错失任何调度机会",
	"If this is true, new queues can be created at application submission time, whether because they are specified as the application’s queue by the submitter or because they are placed there by the user-as-default-queue property. If this is false, any time an app would be placed in a queue that is not specified in the allocations file, it is placed in the “default” queue instead. If a queue placement policy is given in the allocations file, this property is ignored" : "如果该值设置为true,每次应用提交后都会创建一个新的队列。如果设置为false，当某应用没有在分配分请求中指定队列的时候，该应用都会被放到default队列中。如果在请求中制定了队列分配策略，则该属性将被忽略",
	"The interval at which to lock the scheduler and recalculate fair shares, recalculate demand, and check whether anything is due for preemption" : "重新锁住调度器重新计算fair shares和请求以及检查是否有资源可以被用于preemption的时间间隔",
	"Whether to enable aggregation log or not" : "是否开启YARN log的集中存储",
	"How long to keep aggregation logs" : "集中存储的log将被保存多久（秒）",
	"How long to wait between aggregated log retention checks. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful set this too small and you will spam the name node." : "多长时间（秒）检查一次集中存储的log是否到期可以清理。如果设置为0或负数，则该值将会被设置为yarn.log-aggregation.retain-seconds的十分之一。如果该值过小可能会导致频繁想name node发送请求",
	"Where to aggregate logs to" : "集中存储的log将被保存在那，默认为HDFS的/tmp/logs目录",
	"The remote log dir will be created at {yarn.nodemanager.remote-app-log-dir}/${user}/{thisParam}" : "集中存储的log将会被放在{yarn.nodemanager.remote-app-log-dir}/${user}/{本参数}中",
	"update-yarn-scheduler" : "更新调度器",
	"Enable Hive" : "开启 Hive",
	"Launch/shutdown Hive Metastore and HiveServer2 services" : "开启/关闭 Hive Metastore and HiveServer2 服务",
	"Use remote mysql" : "使用远程 mysql 数据库",
	"Set to true to use remote mysql server, false to use local" : "true 为使用远程 mysql 数据库，false 为使用本地 mysql 数据库",
	"Remote mysql server ip" : "远程 mysql 数据库 ip",
	"Valid only when using remote mysql server" : "仅当使用远程 mysql 数据库时需填此项",
	"Hive Metastore username" : "Hive Metastore 用户名",
	"Default to hive for local mysql" : "本地 mysql 数据库默认为 hive",
	"Hive Metastore password" : "Hive Metastore 密码",
	"restart-hive" : "重启 Hive 服务",
	"enable_hive_plugin" : "启动 Ranger Hive 插件",
	"disable_hive_plugin" : "关闭 Ranger Hive 插件",
	"Role" : "角色",
	"Running service" : "运行服务",
	"node_details_tab" : "服务详情",
	"Cores number of each spark executer for query" : "单个查询Spark Executor所用CPU核数",
	"Number of spark executers for query" : "查询Spark Executor数",
	"Memory size of spark driver for query" : "查询Spark Driver内存大小",
	"Memory size of each spark executer for query" : "单个查询Spark Executor内存大小",
	"Resource Configuration":"资源配置类型",
	"Basic":"基础型",
	"Premium":"增强型",
	"The resource configuration of the service":"请选择合适的资源配置类型，快速定义集群配置。",
	"hive execution engine": "hive执行引擎",
	"Whether to execute jobs in parallel": "是否并行执行作业",
	"How many jobs at most can be executed in parallel": "并行执行作业数",
	"Merge small files at the end of a map-reduce job": "hive on mr作业结束时是否合并小文件",
	"Merge small files at the end of a Spark DAG Transformation": "hive on spark作业结束时是否合并小文件",
	"Size of merged files at the end of the job": "作业结束时合并文件的大小(byte)，默认128000000",
	"When the average output file size of a job is less than this number, Hive will start an additional map-reduce job to merge the output files into bigger files. This is only done for map-only jobs if hive.merge.mapfiles is true, and for map-reduce jobs if hive.merge.mapredfiles is true": "作业的输出文件平均大小(byte)小于该值时，hive将启动MapReduce作业将输出文件合并成大文件。如果hive.merge.mapfiles=true时只对仅包含map任务的作业生效，如果hive.merge.mapredfiles=true时对所有MapReduce作业生效。默认5000000",
	"The deploy mode of Spark driver program, Which means to launch driver program locally (\"client\") or remotely (\"cluster\") on one of the nodes inside the cluster":"hive on spark作业中driver程序的部署模式，可选模式cluster和client，两种模式下driver的启动节点分别是集群上某一个slave节点和客户端(注意：client模式下通过beeline提交作业时driver将在主节点启动)",
	"Amount of memory to use for the driver process, i.e. where SparkContext is initialized, in the same format as JVM memory strings with a size unit suffix (\"k\", \"m\", \"g\" or \"t\") (e.g. 512m, 2g)": "hive on spark作业中driver的分配内存(书写格式与jvm内存格式相同，单位k、m、g、t等，例如512m、2g)",
	"Amount of memory to use per executor process, in the same format as JVM memory strings with a size unit suffix (\"k\", \"m\", \"g\" or \"t\") (e.g. 512m, 2g)": "hive on spark作业中每个executor的分配内存(书写格式与jvm内存格式相同，单位k、m、g、t等，例如512m、2g)",
	"The number of cores to use on each executor": "hive on spark作业中每个executor的分配核心数",
	"The number of excutors to use on each job": "hive on spark作业中每个作业分配的executor个数",
	"Session will be closed when it's not accessed for this duration, which can be disabled by setting to zero or negative value": "hiveserver2的session闲置超过该时间时将被关闭，置零或负值时将禁用。需填入时间值，单位(d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec)，不指定时默认msec",
	"Operation will be closed when it's not accessed for this duration of time, which can be disabled by setting to zero value": "hiveserver2的session中operation超过该时间时将被取消，置零或负值时将禁用。需填入时间值，单位(d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec)，不指定时默认msec",
	"The check interval for session/operation timeout, which can be disabled by setting to zero or negative value": "hiveserver2中检查session和operation超时的间隔时间，该值应该大于等于3000msec，置零或负值时将禁用。需填入时间值，单位(d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec)，不指定时默认msec",
	"whether the new YARN-UI v2 is enabled or not. Defaults to false.": "是否启用 YARN WEB UI v2 ，默认启用",
	"JVM heap size for the JobManager, in the same format as JVM memory strings with a size unit suffix (\"k\", \"m\", \"g\" or \"t\") (e.g. 512m, 2g)": "JobManager内存大小(书写格式与jvm内存格式相同，单位k、m、g、t等，例如512m、2g)",
	"JVM heap size for the Taskmanager, in the same format as JVM memory strings with a size unit suffix (\"k\", \"m\", \"g\" or \"t\") (e.g. 512m, 2g)": "Taskmanager内存大小(书写格式与jvm内存格式相同，单位k、m、g、t等，例如512m、2g)",
	"Default parallelism for jobs": "任务默认并行度",
	"The time in days after which a completed job expires and delete from jobmanager.archive.fs.dir": "已完成任务保存时间（单位天）",
	"The timeout in milliseconds for a idle slot in Slot Pool": "slot最大空闲时间（单位毫秒）",
	"The timeout in milliseconds for requesting a slot from Slot Pool": "请求slot超时时间（单位毫秒）",
	"The maximum number of old log files to keep": "要保留的最大日志文件数",
	"Time in seconds to retain user logs. Only applicable if log aggregation is disabled": "保存 YARN 应用日志的时间（以秒为单位）。仅在没有启用日志聚合时生效",
	"Number of seconds after an application finishes before the nodemanager's DeletionService will delete the application's localized file directory and log directory.": "YARN 应用结束后多长时间删掉应用的本地文件目录及日志目录（以秒为单位）",
	"S3 compatible object storage endpoint, QingStor_zone will be ignored if this value is specified. Useful for private cloud senario where public cloud object storage cannot be reached. For public cloud, usually this should not be specified, and should be in s3.<zone>.qingstor.com format if specified.": "兼容 S3 的对象存储的 endpoint, 如果指定了该值 QingStor_zone 将被忽略，常用于私有云中无法访问公有云对象存储的场景。通常公有云不用指定该值，如果指定须以 s3.<zone>.qingstor.com 格式",
	"err_code1": "禁止同时删除多个从节点"
}